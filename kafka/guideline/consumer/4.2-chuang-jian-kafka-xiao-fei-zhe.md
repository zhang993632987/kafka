# 4.2 创建Kafka消费者

在读取消息之前，需要先创建一个<mark style="color:blue;">**KafkaConsumer**</mark>对象。

## 4.2.1 三个必须设置的属性

### **1. bootstrap.servers**

bootstrap.servers指定了连接Kafka集群的字符串。它的作用与KafkaProducer中的bootstrap.servers一样。

### **2. key.deserializer和value.deserializer**

key.deserializer和value.deserializer与生产者的key.serializer和value.serializer类似，只不过它们不是使用指定类把Java对象转成字节数组，而是把字节数组转成Java对象。

<mark style="color:orange;">生成消息所使用的序列化器与读取消息所使用的反序列化器应该是相对应的。</mark>

{% hint style="info" %}
使用Avro和模式注册表进行序列化和反序列化的优势在于：<mark style="color:blue;">**AvroSerializer可以保证写入主题的数据与主题的模式是兼容的**</mark>，也就是说，<mark style="color:blue;">**可以使用相应的反序列化器和模式来反序列化数据**</mark>。另外，不管是在生产者端还是消费者端出现的任何一个与兼容性有关的错误都会被捕捉到，而且这些错误都带有描述性信息，这也就意味着，当出现序列化错误时，无须再费劲地调试字节数组了。
{% endhint %}

## 4.2.2 会话

### **1. session.timeout.ms和heartbeat.interval.ms**

<mark style="color:blue;">**session.timeout.ms指定了消费者可以在多长时间内不与服务器发生交互而仍然被认为还“活着”，默认是10秒。如果消费者没有在session.timeout.ms指定的时间内发送心跳给群组协调器，则会被认为已“死亡”，协调器就会触发再均衡，把分区分配给群组里的其他消费者**</mark>。

<mark style="color:blue;">**heartbeat.interval.ms指定了消费者向协调器发送心跳的频率**</mark>。我们一般会同时设置这两个属性，heartbeat.interval.ms必须比session.timeout.ms小，通常前者是后者的1/3。如果session.timeout.ms是3秒，那么heartbeat.interval.ms就应该是1秒。

**把session.timeout.ms设置得比默认值小，可以更快地检测到崩溃，并从崩溃中恢复，但也会导致不必要的再均衡。把session.timeout.ms设置得比默认值大，可以减少意外的再均衡，但需要更长的时间才能检测到崩溃。**

### **2. max.poll.interval.ms**

这个属性指定了<mark style="color:blue;">**消费者在被认为已经“死亡”之前可以在多长时间内不发起轮询**</mark>**。**

**心跳是通过后台线程发送的，而后台线程有可能在消费者主线程发生死锁的情况下继续发送心跳**，但这个消费者并没有在读取分区里的数据。要想知道消费者是否还在处理消息，最简单的方法是检查它是否还在请求数据。但是，请求之间的时间间隔是很难预测的，它不仅取决于可用的数据量、消费者处理数据的方式，有时还取决于其他服务的延迟。在需要耗费时间来处理每个记录的应用程序中，可以通过max.poll.records来限制返回的数据量，从而限制应用程序在再次调用poll()之前的等待时长。但是，即使设置了max.poll.records，调用poll()的时间间隔仍然很难预测。于是，<mark style="color:red;">**设置max.poll.interval.ms就成了一种保险措施。它必须被设置得足够大，让正常的消费者尽量不触及这个阈值，但又要足够小，避免有问题的消费者给应用程序造成严重影响**</mark>。**这个属性的默认值为5分钟。当这个阈值被触及时，后台线程将向broker发送一个“离开群组”的请求，让broker知道这个消费者已经“死亡”，必须进行群组再均衡，然后停止发送心跳**。

## 4.2.3 吞吐量

### **1. fetch.min.bytes**

这个属性指定了消费者从服务器获取记录的最小字节数，默认是1字节。broker在收到消费者的获取数据请求时，**如果可用数据量小于fetch.min.bytes指定的大小，那么它就会等到有足够可用数据时才将数据返回。**

### **2. fetch.max.wait.ms**

通过设置fetch.min.bytes，可以让Kafka等到有足够多的数据时才将它们返回给消费者，feth.max.wait.ms则用于指定broker等待的时间，默认是500毫秒。**如果没有足够多的数据流入Kafka，那么消费者获取数据的请求就得不到满足，最多会导致500毫秒的延迟。**

### **3. fetch.max.bytes**

这个属性指定了Kafka返回的数据的最大字节数（默认为50 MB）。**消费者会将服务器返回的数据放在内存中，所以这个属性被用于限制消费者用来存放数据的内存大小**。需要注意的是，记录是分批发送给客户端的，如果broker要发送的批次超过了这个属性指定的大小，那么这个限制将被忽略。

### **4. max.poll.records**

这个属性用于**控制单次调用poll()方法返回的记录条数**。可以用它来控制应用程序在进行每一次轮询循环时需要处理的记录条数（不是记录的大小）。

### **5. max.partition.fetch.bytes**

这个属性**指定了服务器从每个分区里返回给消费者的最大字节数**（默认值是1 MB）。当KafkaConsumer.poll()方法返回ConsumerRecords时，从每个分区里返回的记录最多不超过max.partition.fetch.bytes指定的字节。

## 4.2.4 偏移量

### **1. auto.offset.reset**

这个属性指定了消费者在读取一个没有偏移量或偏移量无效（因消费者长时间不在线，偏移量对应的记录已经过期并被删除）的分区时该做何处理。它的默认值是**latest**，意思是说，如果没有有效的偏移量，那么消费者将从最新的记录（在消费者启动之后写入Kafka的记录）开始读取。另一个值是**earliest**，意思是说，如果没有有效的偏移量，那么消费者将从起始位置开始读取记录。如果将auto.offset.reset设置为none，并试图用一个无效的偏移量来读取记录，则消费者将抛出异常。

### **2. enable.auto.commit**

这个属性指定了消费者是否自动提交偏移量，默认值是true。如果它被设置为true，那么还有另外一个属性auto.commit.interval.ms可以用来控制偏移量的提交频率。

{% hint style="info" %}
**offsets.retention.minutes**

**这是broker端的一个配置属性**，需要注意的是，它也会影响消费者的行为。<mark style="color:blue;">**只要消费者群组里有活跃的成员（也就是说，有成员通过发送心跳来保持其身份），群组提交的每一个分区的最后一个偏移量就会被Kafka保留下来，在进行重分配或重启之后就可以获取到这些偏移量**</mark><mark style="color:blue;">。</mark>但是，如果一个消费者群组失去了所有成员，则Kafka只会按照这个属性指定的时间（默认为7天）保留偏移量。一旦偏移量被删除，即使消费者群组又“活”了过来，它也会像一个全新的群组一样，没有了过去的消费记忆。
{% endhint %}

## 4.2.5 协作（增量式）再均衡

### **1. group.id**

group.id不是必需的，它指定了一个消费者属于哪一个消费者群组。可以创建不属于任何一个群组的消费者，只是这种做法不太常见。

### **2. group.instance.id**

这个属性可以是任意具有唯一性的字符串，它为消费者指定了一个固定的唯一值。

### **3. partition.assignment.strategy**

PartitionAssignor根据给定的消费者和它们订阅的主题来决定哪些分区应该被分配给哪个消费者。Kafka提供了几种默认的分配策略。

* <mark style="color:blue;">**区间(range)**</mark>

这个策略会**把每一个主题的若干个连续分区分配给消费者**。假设消费者C1和消费者C2同时订阅了主题T1和主题T2，并且每个主题有3个分区。那么消费者C1有可能会被分配到这两个主题的分区0和分区1，消费者C2则会被分配到这两个主题的分区2。因为每个主题拥有奇数个分区，并且都遵循一样的分配策略，所以第一个消费者会分配到比第二个消费者更多的分区。只要使用了这个策略，并且分区数量无法被消费者数量整除，就会出现这种情况。

* <mark style="color:blue;">**轮询(roundRobin)**</mark>

这个策略会**把所有被订阅的主题的所有分区按顺序逐个分配给消费者**。如果使用轮询策略为消费者C1和消费者C2分配分区，那么消费者C1将分配到主题T1的分区0和分区2以及主题T2的分区1，消费者C2将分配到主题T1的分区1以及主题T2的分区0和分区2。一般来说，如果所有消费者都订阅了相同的主题（这种情况很常见），那么轮询策略会给所有消费者都分配相同数量（或最多就差一个）的分区。

* <mark style="color:blue;">**黏性(sticky)**</mark>

设计黏性分区分配器的目的有两个：一是尽可能均衡地分配分区，二是<mark style="color:blue;">**在进行再均衡时尽可能多地保留原先的分区所有权关系，减少将分区从一个消费者转移给另一个消费者所带来的开销**</mark>。如果所有消费者都订阅了相同的主题，那么黏性分配器初始的分配比例将与轮询分配器一样均衡。后续的重新分配将同样保持均衡，但减少了需要移动的分区的数量。如果同一个群组里的消费者订阅了不同的主题，那么黏性分配器的分配比例将比轮询分配器更加均衡。

* <mark style="color:blue;">**协作黏性(cooperative sticky)**</mark>

这个分配策略与黏性分配器一样，只是它<mark style="color:red;">**支持协作（增量式）再均衡**</mark>，在进行再均衡时消费者可以继续从没有被重新分配的分区读取消息。

## 4.2.6 其他

### **1. client.id**

这个属性可以是任意字符串，broker用它来标识从客户端发送过来的请求，比如获取请求。它通常被用在日志、指标和配额中。

### **2. client.rack**

**在默认情况下，消费者会从每个分区的首领副本那里获取消息**。但是，如果集群跨越了多个数据中心或多个云区域，那么让消费者从位于同一区域的副本那里获取消息就会具有性能和成本方面的优势。<mark style="color:blue;">**要从最近的副本获取消息，需要设置client.rack这个参数，用于标识客户端所在的区域**</mark><mark style="color:blue;">。然后，可以</mark><mark style="color:blue;">**将broker的replica.selector.class参数值改为org.apache.kafka.common.replica.RackAwareReplicaSelector**</mark><mark style="color:blue;">。</mark>

### **3. default.api.timeout.ms**

如果在调用消费者API时没有显式地指定超时时间，那么消费者就会在调用其他API时使用这个属性指定的值。默认值是1分钟，因为它比请求超时时间的默认值大，所以可以将重试时间包含在内。poll()方法是一个例外，因为它需要显式地指定超时时间。

### **4. request.timeout.ms**

这个属性指定了**消费者在收到broker响应之前可以等待的最长时间**。如果broker在指定时间内没有做出响应，那么客户端就会关闭连接并尝试重连。它的默认值是30秒。不建议把它设置得比默认值小。在放弃请求之前要给broker留有足够长的时间来处理其他请求，因为向已经过载的broker发送请求几乎没有什么好处，况且断开并重连只会造成更大的开销。

### **5. receive.buffer.bytes和send.buffer.bytes**

这两个属性分别指定了socket在读写数据时用到的TCP缓冲区大小。如果它们被设置为–1，就使用操作系统的默认值。如果生产者或消费者与broker位于不同的数据中心，则可以适当加大它们的值，因为跨数据中心网络的延迟一般都比较高，而带宽又比较低。
