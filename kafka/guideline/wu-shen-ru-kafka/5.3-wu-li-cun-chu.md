# 5.3 物理存储

<mark style="color:blue;">**Kafka的基本存储单元是分区**</mark>**。分区既无法在多个broker间再细分，也无法在同一个broker的多个磁盘间再细分。所以，分区的大小受单个挂载点可用空间的限制。**

在配置Kafka时，管理员会指定一个用于<mark style="color:blue;">**保存分区数据的目录列表**</mark>，也就是<mark style="color:blue;">**log.dirs**</mark>参数。这个参数一般会包含Kafka将要使用的每一个挂载点的目录。

## 5.3.1分层存储

从2018年年底开始，Kafka社区启动了一个雄心勃勃的项目，为Kafka增加分层存储能力，并计划在3.0中发布。这个项目的动机很简单：<mark style="color:orange;">**之所以使用Kafka存储海量数据，要么是因为吞吐量高，要么是因为需要长时间保留数据**</mark>，但以下几点不容忽视：

* 一个分区可以存储的数据量是有限的。因此，分区数量不仅由产品需求驱动，也受物理磁盘大小的限制。
* 磁盘和集群大小的选择取决于存储需求。但是，如果将延迟和吞吐量作为主要考虑因素，那么集群的规模通常比实际需要的要大，从而增加了成本。
* 在broker间移动分区（当扩展或缩小集群时）所需要的时间是由分区大小决定的。大分区会降低集群的弹性。<mark style="color:orange;">**如今，我们可以充分利用灵活的云部署，所以在进行架构设计时会偏向于追求更大的弹性**</mark>**。**

**在分层存储架构中，Kafka集群配置了两个存储层：**<mark style="color:blue;">**本地存储层**</mark>**和**<mark style="color:blue;">**远程存储层**</mark>**。本地存储层和当前的Kafka存储层一样，使用broker的本地磁盘存储日志片段，远程存储层则使用HDFS、S3等专用存储系统存储日志片段。**

Kafka用户**可以单独为每一层配置保留策略**。由于本地存储的成本通常远高于远程存储，因此本地存储的数据保留时间通常是几小时，甚至更短，而远程存储的保留时间则比较长，可以是几天，甚至几个月。

**本地存储的延迟明显低于远程存储**。对延迟敏感的应用程序通常从本地存储的分区尾部读取数据，因此可以受益于现有的Kafka存储机制，比如可以有效地利用页面缓存。在进行数据回填或故障恢复时，应用程序需要用到旧数据，所以需要从远程存储读取。

<mark style="color:blue;">**分层存储架构让Kafka集群的存储扩展可以独立于内存和CPU，因此可以将Kafka作为一种长期的存储解决方案。这既减少了存储在broker上的数据量，也减少了在进行故障恢复和再均衡时需要复制的数据量。**</mark>远程存储中的日志片段不需要恢复到broker上，当然，如果有必要也可以进行按需恢复。因为不是所有的数据都存储在broker上，所以要延长集群数据保留时间就不再需要扩展集群存储或添加新节点。与此同时，延长系统总体数据保留时间也无须像其他系统那样使用单独的数据管道将数据从Kafka复制到外部存储。

负责开发分层存储特性的团队针对几种不同的场景进行了性能测试。在第一个场景中使用Kafka通常的高吞吐量工作负载。在这个场景中，延迟增加了一点点（从21毫秒增加到了25毫秒），因为broker需要将日志片段发送给远程存储。第二个场景是让一些消费者读取旧数据。在没有使用分层存储的情况下，消费者读取旧数据对延迟有很大的影响（21毫秒对60毫秒），但在启用了分层存储后，影响显著降低（25毫秒对42毫秒）。这是因为分层存储读取是通过网络从HDFS或S3读取的，不会与基于本地磁盘I/O或页面缓存的本地读取产生竞争，让页面缓存只保留新鲜的数据。

所以，<mark style="color:blue;">**除了无限存储、更低的成本和更高的弹性外，分层存储还提供了历史数据读取和实时数据读取之间的隔离**</mark><mark style="color:blue;">。</mark>

## 5.3.2 分区的分配

在创建主题时，Kafka首先要决定如何在broker间分配分区。

**假设你有6个broker，打算创建一个包含10个分区的主题，并且复制系数为3，那么总共会有30个分区副本，它们将被分配给6个broker**，此时，分配方案如下：

* <mark style="color:blue;">**先随机选择一个broker（假设是4），然后使用轮询的方式给每个broker分配分区首领**</mark>。于是，分区0的首领在broker 4上，分区1的首领在broker 5上，分区2的首领在broker 0上（因为只有6个broker），以此类推。
* <mark style="color:blue;">**接下来，从分区首领开始，依次分配跟随者副本**</mark>。如果分区0的首领在broker 4上，那么它的第一个跟随者副本就在broker 5上，第二个跟随者副本就在broker 0上。如果分区1的首领在broker 5上，那么它的第一个跟随者副本就在broker 0上，第二个跟随者副本在broker 1上。
* <mark style="color:blue;">**如果配置了机架信息，那么就不是按照数字顺序而是按照机架交替的方式来选择broker了**</mark>。假设broker 0和broker 1被放置在一个机架上，broker 2和broker 3被放置在另一个机架上。我们不是按照从0到3的顺序来选择broker，而是按照0、2、1、3的顺序来选择，以保证相邻的broker总是位于不同的机架上。于是，如果分区0的首领在broker 2上，那么第一个跟随者副本就在broker 1上，以保证它们位于不同的机架上。因为如果第一个机架离线，则还有其他幸存的副本，所以分区仍然可用。这对所有副本来说都是一样的，因此在机架离线时仍然能够保证可用性。
* 为分区和副本选好合适的broker之后，接下来要决定新分区应该被放在哪个目录。我们会为每个分区分配目录，规则很简单：**计算每个目录里的分区数量，新分区总是会被放在分区数量最少的那个目录**。也就是说，如果添加了一个新磁盘，那么所有新分区都会被放到这个磁盘。这是因为在达到均衡分配的状态之前，新磁盘的分区数量总是最少的。

## 5.3.3 文件管理

**数据保留**是Kafka的一个重要概念。Kafka不会一直保留数据，也不会一直等到消息被所有消费者读取了之后才将其删除。相反，Kafka管理员会为每个主题配置数据保留期限，主题的数据要么在达到指定的时间之后被清除，要么在达到指定的数量之后被清除。

在一个大文件中查找和删除消息既费时又很容易出错，所以我们会把分区分成若干个**片段**。在默认情况下，每个片段包含1 GB或一周的数据，以较小的那个为准。在broker向分区写入数据时，如果触及任意一个上限，就关闭当前文件，并打开一个新文件。

当前正在写入数据的片段叫作**活动片段**。**活动片段永远不会被删除**，所以，如果你配置的保留时间是1天，但片段里包含了5天的数据，那么这些数据就会被保留5天，因为在片段被关闭之前，这些数据是不会被删除的。

{% hint style="warning" %}
<mark style="color:orange;">**broker会为分区的每一个打开的日志片段分配一个文件句柄，哪怕是非活动片段。这样就会打开很多文件句柄，因此必须根据实际情况对操作系统做一些调优。**</mark>
{% endhint %}

## 5.3.4 文件格式

每个日志片段被保存在一个单独的数据文件中，文件中包含了消息和偏移量。<mark style="color:blue;">**保存在磁盘上的数据格式与生产者发送给服务器的消息格式以及服务器发送给消费者的消息格式是一样的**</mark><mark style="color:blue;">。</mark>因为磁盘存储和网络传输采用了相同的格式，所以Kafka可以使用**零复制技术**向消费者发送消息，并避免对生产者压缩过的消息进行解压和再压缩。

Kafka消息由<mark style="color:blue;">**有效负载**</mark>和<mark style="color:blue;">**系统标头**</mark>组成。有效负载包括一个可选的键、值和一些可选的用户标头，其中每个标头也是一个键–值对。

**生产者是以批次的方式发送消息的**。如果每次只发送一条消息，那么使用批次反而会增加开销。但如果每次发送两条或更多的消息，那么使用批次就可以节约空间，减少网络带宽和磁盘的使用。因为Kafka会为每个分区创建一个单独的批次，所以写入的分区越少，生产者的效率就越高。需要注意的是，生产者可以在同一个生产请求中包含多个批次。如果生产者端使用了压缩（推荐这么做），那么更大的批次将意味着不管是通过网络传输还是磁盘保存都能获得更好的压缩比。

## 5.3.5 索引

消费者可以从Kafka任意可用的偏移量位置开始读取消息。假设消费者希望从偏移量100开始读取1 MB消息，那么broker就必须立即定位到偏移量100（可能是在分区的任意一个片段里），然后从这个位置开始读取消息。<mark style="color:blue;">**为了帮助broker更快定位到指定的偏移量，Kafka为每个分区维护了一个索引**</mark><mark style="color:blue;">。</mark><mark style="color:blue;">**该索引将偏移量与片段文件以及偏移量在文件中的位置做了映射**</mark>**。**

类似地，Kafka还有**第二个索引**，该索引**将时间戳与消息偏移量做了映射**。在按时间戳搜索消息时会用到这个索引。这种搜索方式在Kafka Streams中使用广泛，在一些故障转移场景中也很有用。

索引也会被分成片段，所以，在删除消息时也可以删除相应的索引。Kafka没有为索引维护校验和。如果索引损坏，那么Kafka将通过重新读取消息并记录偏移量和位置来再次生成索引。如果有必要，管理员也可以删除索引，这样做绝对安全（尽管可能需要较长的恢复时间），因为Kafka会自动重新生成索引。
