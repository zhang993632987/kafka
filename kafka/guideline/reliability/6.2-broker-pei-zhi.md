# 6.2 broker配置

broker中有3个配置参数会影响Kafka的消息存储可靠性。与其他配置参数一样，它们既可以配置在broker级别，用于控制所有主题的行为，也可以配置在主题级别，用于控制个别主题的行为。

## 6.2.1 复制系数

主题级别的配置参数是 <mark style="color:blue;">**replication.factor**</mark>。在broker级别，可以通过<mark style="color:blue;">**default.replication.factor**</mark> 来设置自动创建的主题的复制系数。

那么该如何确定一个主题需要几个副本呢？这个时候需要考虑以下因素：

* <mark style="color:blue;">**可用性**</mark>：**副本越多，可用性就越高**。
* <mark style="color:blue;">**持久性**</mark>：每个副本都包含了一个分区的所有数据。**如果有更多的副本，并且这些副本位于不同的存储设备中，那么丢失所有副本的概率就降低了。**
* <mark style="color:blue;">**吞吐量**</mark>：**每增加一个副本都会增加broker内的复制流量**。如果以10 MBps的速率向一个分区发送数据，并且只有1个副本，那么不会增加任何的复制流量。如果有2个副本，则会增加10 MBps的复制流量，3个副本会增加20 MBps的复制流量，5个副本会增加40 MBps的复制流量。在规划集群大小和容量时，需要把这个考虑在内。
* <mark style="color:blue;">**端到端延迟**</mark>：每一条记录必须被复制到所有同步副本之后才能被消费者读取。从理论上讲，**副本越多，出现滞后的可能性就越大，因此会降低消费者的读取速度**。在实际当中，如果一个broker由于各种原因变慢，那么它就会影响所有的客户端，而不管复制系数是多少。
* <mark style="color:blue;">**成本**</mark>**：**一般来说，出于成本方面的考虑，非关键数据的复制系数应该小于3。**数据副本越多，存储和网络成本就越高。**因为很多存储系统已经将每个数据块复制了3次，所以有时候可以将Kafka的复制系数设置为2，以此来降低成本。需要注意的是，与复制系数3相比，这样做仍然会降低可用性，但可以由存储设备来提供持久性保证。

**副本的位置分布也很重要。**<mark style="color:blue;">**Kafka可以确保分区的每个副本被放在不同的broker上**</mark>。但是，在某些情况下，这样仍然不够安全。如果一个分区的所有副本所在的broker位于同一个机架上，那么一旦机架的交换机发生故障，不管设置了多大的复制系数，这个分区都不可用。<mark style="color:blue;">**为了避免机架级别的故障，建议把broker分布在多个不同的机架上，并通过 broker.rack 参数配置每个broker所在的机架的名字**</mark>**。**如果配置了机架名字，那么Kafka就会保证分区的副本被分布在多个机架上，从而获得更高的可用性。<mark style="color:blue;">**如果是在云端运行Kafka，则可以将可用区域视为机架。**</mark>

## 6.2.2 不彻底的首领选举

<mark style="color:blue;">**unclean.leader.election.enable**</mark> 只能在broker级别（实际上是在集群范围内）配置，它的默认值是 false。

当分区的首领不可用时，一个同步副本将被选举为新首领。如果在选举过程中未丢失数据，也就是说所有同步副本都包含了已提交的数据，那么这个选举就是**“彻底”**的。

<mark style="color:orange;">**如果允许不同步副本成为首领，那么就要承担丢失数据和消费者读取到不一致的数据的风险。如果不允许它们成为首领，那么就要接受较低的可用性，因为必须等待原先的首领恢复到可用状态。**</mark>

## 6.2.3 最少同步副本

<mark style="color:blue;">**min.insync.replicas**</mark> 参数可以配置在主题级别和broker级别。

尽管为一个主题配置了3个副本，还是会出现**只剩下一个同步副本**的情况。如果这个同步副本变为不可用，则必须在可用性和一致性之间做出选择，而这是一个两难的选择。根据Kafka对可靠性保证的定义，一条消息只有在被写入所有同步副本之后才被认为是已提交的，但**如果这里的“所有”只包含一个同步副本，那么当这个副本变为不可用时，数据就有可能丢失。**

**如果想确保已提交的数据被写入不止一个副本，就要把最少同步副本设置得大一些。对于一个包含3个副本的主题，如果 min.insync.replicas 被设置为2，那么至少需要有两个同步副本才能向分区写入数据。**如果有两个副本变为不可用，那么broker就会停止接受生产者的请求。尝试发送数据的生产者会收到 **NotEnoughReplicasException** 异常，不过消费者仍然可以继续读取已有的数据。实际上，如果使用这样的配置，那么当只剩下一个同步副本时，它就变成只读的了。

## 6.2.4 保持副本同步

一个副本可能在两种情况下变得不同步：要么它**与ZooKeeper断开连接**，要么它**从首领复制消息滞后**。对于这两种情况，Kafka提供了两个broker端的配置参数。

**zookeeper.session.timeout.ms** 是允许broker不向ZooKeeper发送心跳的时间间隔。如果超过这个时间不发送心跳，则ZooKeeper会认为broker已经“死亡”，并将其从集群中移除。在Kafka 2.5.0中，这个参数的默认值从6秒增加到了18秒，以提高Kafka集群在云端的稳定性，因为云环境的网络延迟更加多变。一般来说，我们希望将这个值设置得足够大，以避免因垃圾回收停顿或网络条件造成的随机抖动，但又要设置得足够小，以确保及时检测到确实已经发生故障的broker。

如果一个副本未能在 **replica.lag.time.max.ms** 指定的时间内从首领复制数据或赶上首领，那么它将变成不同步副本。在Kafka 2.5.0中，这个参数的默认值从10秒增加到了30秒，以提高集群的弹性，并避免不必要的抖动。需要注意的是，这个值也会影响消费者的最大延迟——值越大，等待一条消息被写入所有副本并可被消费者读取的时间就越长，最长可达30秒。

## 6.2.5 持久化到磁盘

即使消息还没有被持久化到磁盘上，Kafka也可以向生产者发出确认，这取决于已接收到消息的副本的数量。<mark style="color:blue;">**Kafka会在重启之前和关闭日志片段（默认1 GB大小时关闭）时将消息冲刷到磁盘上，或者等到Linux系统页面缓存被填满时冲刷**</mark>**。**其背后的想法是，拥有3台放置在不同机架或可用区域的机器，并在每台机器上放置一份数据副本比只将消息写入首领的磁盘更加安全，因为两个不同的机架或可用区域同时发生故障的可能性非常小。不过，也可以让broker更频繁地将消息持久化到磁盘上。配置参数 <mark style="color:blue;">**flush.messages**</mark> 用于控制未同步到磁盘的最大消息数量，<mark style="color:blue;">**flush.ms**</mark> 用于控制同步频率。在配置这些参数之前，最好先了解一下 <mark style="color:blue;">**fsync**</mark> 是如何影响Kafka的吞吐量的以及如何尽量避开它的缺点。
