# 事务不能解决哪些问题

**在Kafka中加入事务是为了提供**<mark style="color:blue;">**多分区原子写入**</mark>**（不是读取），并隔离流式处理应用程序中的**<mark style="color:blue;">**“僵尸”生产者**</mark>**。**<mark style="color:orange;">**在“消费–处理–生产”流式处理任务中，事务为我们提供了精确一次性保证。在其他场景中，事务要么不起作用，要么需要做额外的工作才能获得我们想要的结果。**</mark>

下面是Kafka事务无法实现精确一次性保证的几种场景。

## **在流式处理中执行外部操作**

假设流式处理应用程序在处理数据时需要向用户发送电子邮件。在应用程序中启用精确一次性语义并不能保证邮件只发送一次，这个保证只适用于将记录写入Kafka。使用序列号去重，或者使用标记中止或取消事务在Kafka中是有效的，但它不会撤销已发送的电子邮件。在流式处理应用程序中执行的任何带有外部效果的操作都是如此：调用REST API、写入文件，等等。

## **从Kafka中读取数据并写入数据库**

在这种情况下，应用程序会将数据写入外部数据库，而不是Kafka。这里没有生产者参与，我们用数据库驱动器（如JDBC）将记录写入数据库，消费者会将偏移量提交给Kafka。没有任何一种机制允许将外部数据库写入操作与向Kafka提交偏移量的操作放在同一个事务中。不过，我们**可以在数据库中维护偏移量，并在一个事务中将数据和偏移量一起提交到数据库——这将依赖于数据库的事务保证机制而不是Kafka的事务保证机制**。

## **从一个数据库读取数据写入Kafka，再从Kafka将数据写入另一个数据库**

Kafka并不支持这种端到端的事务保证。除了很难保证在同一个事务中提交记录和偏移量，还有另外一个难点：**Kafka的read\_committed隔离级别太弱了，根本无法保留数据库的事务**。**消费者不仅看不到未提交的消息，也不保证可以看到事务中已提交的所有消息，因为消息在某些主题上可能会滞后，而消费者没有事务的边界信息，所以它不知道事务何时开始和结束，也不知道看到的是部分消息还是全部消息。**

## **将数据从一个集群复制到另一个集群**

将数据从一个Kafka集群复制到另一个集群是有可能支持精确一次性保证的。

但这并不能保证事务是原子的。如果一个应用程序以事务的方式生成了几条记录和偏移量，然后MirrorMaker 2.0将它们复制到了另一个Kafka集群，那么在复制过程中事务属性就有可能会丢失。造成事务属性丢失的原因与将数据从Kafka复制到关系数据库一样：从Kafka读取数据的消费者并不知道或者能够保证已经读取了事务的所有记录。如果它只订阅了部分主题，那么就会只复制事务的一部分记录。

## **发布和订阅模式**

事务为发布和订阅模式提供了一些保证：配置了read\_committed隔离级别的消费者将看不到已中止事务的消息，但这种保证并不是精确一次性的。消费者可以多次处理一条消息，具体取决于它们的偏移量提交逻辑。

**对于发布和订阅模式，Kafka提供的保证与JMS事务类似，消费者需要配置成read\_committed隔离级别，以保证未提交的事务对消费者是不可见的**。JMS broker对所有消费者隐藏了未提交的事务。

<mark style="color:red;">**我们要避免的一种模式是在发布消息之后等待另一个应用程序响应，然后才提交事务，而那个应用程序直到事务被提交之后才能收到消息，从而导致死锁。**</mark>

{% hint style="info" %}
## **发件箱模式**

微服务通常需要在一个原子事务中更新数据库并向Kafka发布消息，要么两个操作都生效，要么都不生效。

这个问题的一种常见解决方案是使用**发件箱模式**。<mark style="color:blue;">**微服务只会将消息发布到一个Kafka主题（也就是“发件箱”），然后另外一个独立的消息中继服务会从Kafka读取消息并更新数据库。因为Kafka不会保证数据库操作的精确一次性更新，所以需要确保数据库更新是幂等的。**</mark>

**这个模式可以保证消息最终到达Kafka、主题消费者和数据库，或者都不到达。**

这个模式的反向模式是将数据库作为发件箱，另外一个中继服务将确保将数据库更新也作为消息发送给Kafka。如果可以使用关系数据库内置的约束（比如唯一索引和外键），那么这种模式就是首选。
{% endhint %}
