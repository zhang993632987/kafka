# 工作原理

每个日志片段可以分为以下两个部分：

* **干净的部分**：这些消息之前被压实过，每个键只有一个对应的值，这个值是上一次压实时保留下来的。
* **浑浊的部分**：这些消息是在上一次压实之后写入的。

如果启用了压实功能（通过配置 **log.cleaner.enabled** 参数来开启），那么 broker 在启动时会创建一个**压实管理器线程**和一些**压实工作线程**来执行压实任务。这些线程会选择**浑浊率**（浑浊的消息占分区总体消息的比例）最高的分区来压实。

1. 为了压实分区，压实线程会读取分区的浑浊部分，并在内存中创建一个 map。map 的每个元素都包含消息键的哈希值（16字节）和上一条具有相同键的消息的偏移量（8字节）。
2. 在创建好 map 后，压实线程会开始从干净的片段读取消息，它会先读取最旧的消息，把它们的内容与 map 中的内容进行比对。对于每一条消息，它会检查消息的键是否存在于 map 中：
   * 如果不存在，则说明这条消息的值是最新的，就把它复制到替换片段上。
   * 如果键已存在，就忽略这条消息，因为后面会有一条更新的包含相同键的消息。
3. 在复制完所有消息后，将替换片段与原始片段进行交换，然后开始压实下一个片段。完成整个压实过程后，每一个键对应一条消息，这些消息的值都是最新的。

> Kafka 管理员可以配置压实线程在执行压实时可以为 map 分配多少内存。每个线程都会创建自己的 map，但这个参数指的是所有线程可使用的内存总大小。如果你为 map 分配了 1 GB 内存，并使用了 5 个压实线程，那么每个线程将可以使用 200 MB 内存。
>
> **Kafka 不要求这个 map 可以放下整个分区的浑浊部分，但至少要能够放下一个片段的浑浊部分，否则 Kafka 会报错。**管理员要么为 map 分配更多的内存，要么减少压实线程数量。
>
> 如果有几个片段都可以被放进 map，那么 Kafka 将从最旧的片段开始压实，其他片段则继续保持浑浊，等待下一轮压实。
