# 分层存储

## 动机

从 2018 年年底开始，Kafka 社区启动了一个雄心勃勃的项目，为 Kafka 增加**分层存储**能力，并计划在 3.0 中发布。这个**项目的动机**很简单：**之所以使用 Kafka 存储海量数据，要么是因为吞吐量高，要么是因为需要长时间保留数据**，但以下几点不容忽视：

* **一个分区可以存储的数据量是有限的**。因此，分区数量不仅由产品需求驱动，也受物理磁盘大小的限制。
* **磁盘和集群大小的选择取决于存储需求**。但是，**如果将延迟和吞吐量作为主要考虑因素，那么集群的规模通常比实际需要的要大，从而增加了成本**。
* 在 broker 间移动分区（当扩展或缩小集群时）所需要的时间是由分区大小决定的。**大分区会降低集群的弹性**。<mark style="color:orange;">**如今，我们可以充分利用灵活的云部署，所以在进行架构设计时会偏向于追求更大的弹性**</mark>**。**

## **分层存储特性**

* **在分层存储架构中，Kafka 集群配置了两个存储层：**<mark style="color:blue;">**本地存储层**</mark>**和**<mark style="color:blue;">**远程存储层**</mark>**。**
  * **本地存储层和当前的Kafka存储层一样，使用 broker 的本地磁盘存储日志片段**
  * **远程存储层则使用 HDFS、S3 等专用存储系统存储日志片段**
* **Kafka 用户可以单独为每一层配置保留策略**。
  * 由于本地存储的成本通常远高于远程存储，因此本地存储的数据保留时间通常是几小时，甚至更短
  * 而远程存储的保留时间则比较长，可以是几天，甚至几个月
* **本地存储的延迟明显低于远程存储**。
  * 对延迟敏感的应用程序通常从本地存储的分区尾部读取数据，因此可以受益于现有的 Kafka 存储机制，比如可以有效地利用页面缓存。
  * 在进行数据回填或故障恢复时，应用程序需要用到旧数据，所以需要从远程存储读取。
* **分层存储架构让 Kafka 集群的存储扩展可以独立于内存和 CPU，因此可以将 Kafka 作为一种长期的存储解决方案。**
  * 这既减少了存储在 broker 上的数据量，也减少了在进行故障恢复和再均衡时需要复制的数据量。远程存储中的日志片段不需要恢复到 broker 上，当然，如果有必要也可以进行按需恢复。
  * 因为不是所有的数据都存储在 broker 上，所以要延长集群数据保留时间就不再需要扩展集群存储或添加新节点。与此同时，延长系统总体数据保留时间也无须像其他系统那样使用单独的数据管道将数据从 Kafka 复制到外部存储。

所以，<mark style="color:blue;">**除了无限存储、更低的成本和更高的弹性外，分层存储还提供了历史数据读取和实时数据读取之间的隔离**</mark><mark style="color:blue;">。</mark>

> 负责开发分层存储特性的团队针对几种不同的场景进行了性能测试。
>
> 在第一个场景中使用 Kafka 通常的高吞吐量工作负载。在这个场景中，延迟增加了一点点（从 21 毫秒增加到了 25 毫秒），因为 broker 需要将日志片段发送给远程存储。
>
> 第二个场景是让一些消费者读取旧数据。在没有使用分层存储的情况下，消费者读取旧数据对延迟有很大的影响（21 毫秒对 60 毫秒），但在启用了分层存储后，影响显著降低（25 毫秒对 42毫秒）。这是因为分层存储读取是通过网络从 HDFS 或 S3 读取的，不会与基于本地磁盘 I/O 或页面缓存的本地读取产生竞争，让页面缓存只保留新鲜的数据。
